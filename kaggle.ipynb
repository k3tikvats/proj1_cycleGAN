{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12513587,"sourceType":"datasetVersion","datasetId":7898441}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q rasterio","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:30.018075Z","iopub.execute_input":"2025-07-21T21:52:30.018947Z","iopub.status.idle":"2025-07-21T21:52:33.882564Z","shell.execute_reply.started":"2025-07-21T21:52:30.018916Z","shell.execute_reply":"2025-07-21T21:52:33.881158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q piq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:33.884785Z","iopub.execute_input":"2025-07-21T21:52:33.885170Z","iopub.status.idle":"2025-07-21T21:52:37.786835Z","shell.execute_reply.started":"2025-07-21T21:52:33.885133Z","shell.execute_reply":"2025-07-21T21:52:37.785731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import rasterio\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2, os\nfrom glob import glob\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport random\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader, random_split\nfrom tqdm import tqdm\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:37.788753Z","iopub.execute_input":"2025-07-21T21:52:37.789136Z","iopub.status.idle":"2025-07-21T21:52:37.795688Z","shell.execute_reply.started":"2025-07-21T21:52:37.789103Z","shell.execute_reply":"2025-07-21T21:52:37.794592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sar_dir = '/kaggle/input/sar-images/ROIs2017_winter_s1/ROIs2017_winter'\neo_dir = '/kaggle/input/sar-images/ROIs2017_winter_s2/ROIs2017_winter'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:37.798132Z","iopub.execute_input":"2025-07-21T21:52:37.798408Z","iopub.status.idle":"2025-07-21T21:52:37.818603Z","shell.execute_reply.started":"2025-07-21T21:52:37.798388Z","shell.execute_reply":"2025-07-21T21:52:37.817621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:37.819708Z","iopub.execute_input":"2025-07-21T21:52:37.820163Z","iopub.status.idle":"2025-07-21T21:52:37.839881Z","shell.execute_reply.started":"2025-07-21T21:52:37.820127Z","shell.execute_reply":"2025-07-21T21:52:37.838806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sar_subdirs = sorted(os.listdir(sar_dir))\neo_subdirs = sorted(os.listdir(eo_dir))\nassert len(sar_subdirs) == len(eo_subdirs), \"SAR and EO folder counts do not match\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:37.841134Z","iopub.execute_input":"2025-07-21T21:52:37.841428Z","iopub.status.idle":"2025-07-21T21:52:37.868365Z","shell.execute_reply.started":"2025-07-21T21:52:37.841405Z","shell.execute_reply":"2025-07-21T21:52:37.867435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sar_paths = []\neo_paths = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:37.869429Z","iopub.execute_input":"2025-07-21T21:52:37.869725Z","iopub.status.idle":"2025-07-21T21:52:37.875303Z","shell.execute_reply.started":"2025-07-21T21:52:37.869701Z","shell.execute_reply":"2025-07-21T21:52:37.873910Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for s_sub, e_sub in zip(sar_subdirs, eo_subdirs):\n    # Verify directory matching (remove s1/s2 prefix for comparison)\n    assert s_sub.replace(\"s1_\", \"\") == e_sub.replace(\"s2_\", \"\"), f\"Unmatched subdirs: {s_sub}, {e_sub}\"\n\n    sar_sub_path = os.path.join(sar_dir, s_sub)\n    eo_sub_path = os.path.join(eo_dir, e_sub)\n\n    sar_files = sorted(os.listdir(sar_sub_path))\n    eo_files = sorted(os.listdir(eo_sub_path))\n\n    # FIXED: Proper filename matching\n    for sar_fname in sar_files:\n        # Convert SAR filename to corresponding EO filename\n        eo_fname = sar_fname.replace('_s1_', '_s2_')  # s1 → s2 conversion\n        \n        # Verify the EO file actually exists\n        if eo_fname in eo_files:\n            sar_paths.append(os.path.join(sar_sub_path, sar_fname))\n            eo_paths.append(os.path.join(eo_sub_path, eo_fname))\n        else:\n            print(f\"Warning: No matching EO file for {sar_fname}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:37.876350Z","iopub.execute_input":"2025-07-21T21:52:37.876599Z","iopub.status.idle":"2025-07-21T21:52:38.300420Z","shell.execute_reply.started":"2025-07-21T21:52:37.876579Z","shell.execute_reply":"2025-07-21T21:52:38.299520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Length of whole dataset is {len(sar_paths)} pairs\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.301422Z","iopub.execute_input":"2025-07-21T21:52:38.301682Z","iopub.status.idle":"2025-07-21T21:52:38.308263Z","shell.execute_reply.started":"2025-07-21T21:52:38.301661Z","shell.execute_reply":"2025-07-21T21:52:38.307349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sar_paths = sar_paths[:5000]\neo_paths = eo_paths[:5000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.311231Z","iopub.execute_input":"2025-07-21T21:52:38.311506Z","iopub.status.idle":"2025-07-21T21:52:38.332997Z","shell.execute_reply.started":"2025-07-21T21:52:38.311485Z","shell.execute_reply":"2025-07-21T21:52:38.331944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalize(img):\n    img = img.astype(np.float32)\n    img -= img.min()\n    img /= (img.max() + 1e-6)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.334048Z","iopub.execute_input":"2025-07-21T21:52:38.334924Z","iopub.status.idle":"2025-07-21T21:52:38.351522Z","shell.execute_reply.started":"2025-07-21T21:52:38.334876Z","shell.execute_reply":"2025-07-21T21:52:38.350405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SARToEODataset(Dataset):\n    def __init__(self, sar_paths, eo_paths, patch_size=256, output_mode='rgb'):\n        \n        # Define band indices for Sentinel-2 (0-based)\n        self.bands = {\n            'RGB': [3, 2, 1],      # B4, B3, B2\n            'NIR_SWIR': [7, 10, 4],     # B8, B11, B5\n            'RGB_NIR': [3, 2, 1, 7] # B4, B3, B2, B8\n        }\n        self.sar_paths = sar_paths\n        self.eo_paths = eo_paths\n        self.patch_size = patch_size\n        self.output_mode = output_mode\n\n    def __len__(self):\n        return len(self.sar_paths)  # Assuming sar_paths and eo_paths have same length\n\n    def __getitem__(self, idx):\n        sar = self.read_image(self.sar_paths[idx], bands=[0, 1])  # VV, VH\n        eo_bands = self.bands[self.output_mode]\n        eo = self.read_image(self.eo_paths[idx], bands=eo_bands)\n        \n        sar = torch.from_numpy(sar).float()\n        eo = torch.from_numpy(eo).float()\n        return sar, eo\n\n    def read_image(self, path, bands):\n        with rasterio.open(path) as src:\n            img = []\n            raw_band_data = []\n            for b in bands:\n                band_data = normalize(src.read(b + 1))  # rasterio bands start at 1\n                raw_band_data.append(band_data)\n            \n            if bands == [0,1]:\n                vv, vh = raw_band_data\n                vv_vh_ratio = np.divide(vv, vh + 1e-6)\n                img = [vv, vh, vv_vh_ratio]\n            else:\n                img = raw_band_data\n\n            img = np.stack(img, axis=0)\n            img = img[:, :self.patch_size, :self.patch_size]\n            return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.352798Z","iopub.execute_input":"2025-07-21T21:52:38.353318Z","iopub.status.idle":"2025-07-21T21:52:38.372761Z","shell.execute_reply.started":"2025-07-21T21:52:38.353281Z","shell.execute_reply":"2025-07-21T21:52:38.371766Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResnetBlock(nn.Module):\n    def __init__(self, dim, norm_layer=nn.InstanceNorm2d):\n        super().__init__()\n        self.conv_block = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n            norm_layer(dim),\n            nn.ReLU(True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n            norm_layer(dim)\n        )\n    def forward(self, x):\n        return x + self.conv_block(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.373886Z","iopub.execute_input":"2025-07-21T21:52:38.374175Z","iopub.status.idle":"2025-07-21T21:52:38.395509Z","shell.execute_reply.started":"2025-07-21T21:52:38.374152Z","shell.execute_reply":"2025-07-21T21:52:38.394574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResnetGenerator(nn.Module):\n    def __init__(self, input_nc, output_nc, ngf=64, n_blocks=9, norm_layer=nn.InstanceNorm2d):\n        super().__init__()\n\n        model = [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0),\n            norm_layer(ngf),\n            nn.ReLU(inplace=True)\n        ]\n\n        # Downsampling\n        n_downsampling = 2\n        for i in range(n_downsampling):\n            mult = 2 ** i\n            model += [\n                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n                norm_layer(ngf * mult * 2),\n                nn.ReLU(inplace=True)\n            ]\n\n        # Residual blocks\n        mult = 2 ** n_downsampling\n        for _ in range(n_blocks):\n            model += [ResnetBlock(ngf * mult, norm_layer=norm_layer)]\n\n        # Upsampling\n        for i in range(n_downsampling):\n            mult = 2 ** (n_downsampling - i)\n            model += [\n                nn.ConvTranspose2d(ngf * mult, ngf * mult // 2, kernel_size=3, stride=2, padding=1, output_padding=1),\n                norm_layer(ngf * mult // 2),\n                nn.ReLU(inplace=True)\n            ]\n\n        # Output layer\n        model += [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0),\n            nn.Tanh()\n        ]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.396549Z","iopub.execute_input":"2025-07-21T21:52:38.396836Z","iopub.status.idle":"2025-07-21T21:52:38.421318Z","shell.execute_reply.started":"2025-07-21T21:52:38.396812Z","shell.execute_reply":"2025-07-21T21:52:38.420476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class NLayerDiscriminator(nn.Module):\n    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.InstanceNorm2d):\n        super().__init__()\n        kw = 4\n        padw = 1\n\n        sequence = [\n            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n            nn.LeakyReLU(0.2, inplace=True)\n        ]\n\n        nf_mult = 1\n        for n in range(1, n_layers):\n            nf_mult_prev = nf_mult\n            nf_mult = min(2 ** n, 8)\n            sequence += [\n                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw),\n                norm_layer(ndf * nf_mult),\n                nn.LeakyReLU(0.2, inplace=True)\n            ]\n\n        nf_mult_prev = nf_mult\n        nf_mult = min(2 ** n_layers, 8)\n        sequence += [\n            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw),\n            norm_layer(ndf * nf_mult),\n            nn.LeakyReLU(0.2, inplace=True)\n        ]\n\n        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.422353Z","iopub.execute_input":"2025-07-21T21:52:38.422641Z","iopub.status.idle":"2025-07-21T21:52:38.437520Z","shell.execute_reply.started":"2025-07-21T21:52:38.422610Z","shell.execute_reply":"2025-07-21T21:52:38.436612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"G_sar2rgb = ResnetGenerator(input_nc=3, output_nc=3)\nG_rgb2sar = ResnetGenerator(input_nc=3, output_nc=3)\n\nD_sar = NLayerDiscriminator(input_nc=3)\nD_rgb = NLayerDiscriminator(input_nc=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.438493Z","iopub.execute_input":"2025-07-21T21:52:38.438739Z","iopub.status.idle":"2025-07-21T21:52:38.730513Z","shell.execute_reply.started":"2025-07-21T21:52:38.438722Z","shell.execute_reply":"2025-07-21T21:52:38.729526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_tensor_image(img_tensor, title='', cmap=None, bands=None):\n    \"\"\"\n    Convert CHW tensor to HWC image and display/save with proper handling.\n    \"\"\"\n    img = img_tensor.detach().cpu().numpy()\n    \n    if len(img.shape) == 3:\n        if bands is not None:\n            img = img[bands]\n        if img.shape[0] == 1:\n            img = img[0]\n        else:\n            img = img.transpose(1, 2, 0)\n\n    # Normalize to [0, 1]\n    img = (img - img.min()) / (img.max() - img.min() + 1e-5)\n\n    plt.imshow(img, cmap=cmap)\n    plt.title(title)\n    plt.axis('off')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.731554Z","iopub.execute_input":"2025-07-21T21:52:38.731826Z","iopub.status.idle":"2025-07-21T21:52:38.738305Z","shell.execute_reply.started":"2025-07-21T21:52:38.731802Z","shell.execute_reply":"2025-07-21T21:52:38.737339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_sample_images(epoch, num_samples=3):\n    self.G_AB.eval()\n    with torch.no_grad():\n        val_iter = iter(self.val_loader)\n        for i in range(num_samples):\n            try:\n                real_A, real_B = next(val_iter)\n            except StopIteration:\n                break\n            real_A = real_A.to(self.device)\n            real_B = real_B.to(self.device)\n            fake_B = self.G_AB(real_A)\n\n            plt.figure(figsize=(12, 4))\n            # SAR input (assume 2 or 3 channels: VV, VH, VV/VH)\n            plt.subplot(1, 3, 1)\n            show_tensor_image(real_A[0], 'Input SAR', cmap='gray')\n\n            # Real EO (assume first 3 bands are RGB)\n            plt.subplot(1, 3, 2)\n            show_tensor_image(real_B[0], 'Real EO', bands=[0, 1, 2])\n\n            # Fake EO\n            plt.subplot(1, 3, 3)\n            show_tensor_image(fake_B[0], 'Generated EO', bands=[0, 1, 2])\n\n            plt.tight_layout()\n            plt.savefig(f\"{self.output_dir}/images/epoch_{epoch}_sample_{i}.png\")\n            plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.739490Z","iopub.execute_input":"2025-07-21T21:52:38.739872Z","iopub.status.idle":"2025-07-21T21:52:38.757640Z","shell.execute_reply.started":"2025-07-21T21:52:38.739841Z","shell.execute_reply":"2025-07-21T21:52:38.756547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport torch\n\nclass ImagePool:\n    \"\"\"History buffer of generated images for discriminator training.\"\"\"\n    def __init__(self, pool_size: int):\n        self.pool_size = pool_size\n        self.images = []\n\n    def query(self, images: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        images: a batch of generated images (N,C,H,W)\n        Returns a batch of images to use for D training: either\n        images from pool or the current images, randomly replaced.\n        \"\"\"\n        if self.pool_size == 0:\n            return images\n        return_images = []\n        for img in images:\n            img = torch.unsqueeze(img, 0)\n            if len(self.images) < self.pool_size:\n                # fill pool\n                self.images.append(img)\n                return_images.append(img)\n            else:\n                if random.random() > 0.5:\n                    # use image from pool, replace it\n                    idx = random.randint(0, self.pool_size - 1)\n                    tmp = self.images[idx].clone()\n                    self.images[idx] = img\n                    return_images.append(tmp)\n                else:\n                    return_images.append(img)\n        return torch.cat(return_images, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.758738Z","iopub.execute_input":"2025-07-21T21:52:38.759282Z","iopub.status.idle":"2025-07-21T21:52:38.777982Z","shell.execute_reply.started":"2025-07-21T21:52:38.759236Z","shell.execute_reply":"2025-07-21T21:52:38.776967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\nclass ImagePool:\n    \"\"\"Image buffer that stores previously generated images to stabilize training.\n    \n    This buffer enables us to update discriminators using a history of generated images\n    rather than only the most recently generated images.\n    \"\"\"\n    def __init__(self, pool_size):\n        self.pool_size = pool_size\n        if self.pool_size > 0:\n            self.num_imgs = 0\n            self.images = []\n    \n    def query(self, images):\n        \"\"\"Return images from the pool.\n        \n        Parameters:\n            images: the latest generated images from the generator\n        Returns:\n            images from the buffer.\n        \n        By 50/100, the buffer will return input images.\n        By 50/100, the buffer will return images previously stored in the buffer,\n        and insert the current images to the buffer.\n        \"\"\"\n        if self.pool_size == 0:  # if buffer size is 0, do nothing\n            return images\n        \n        return_images = []\n        for image in images:\n            image = torch.unsqueeze(image.data, 0)\n            if self.num_imgs < self.pool_size:   # if buffer not full\n                self.num_imgs = self.num_imgs + 1\n                self.images.append(image)\n                return_images.append(image)\n            else:\n                p = random.uniform(0, 1)\n                if p > 0.5:  # 50% chance to return a previously stored image\n                    random_id = random.randint(0, self.pool_size - 1)\n                    tmp = self.images[random_id].clone()\n                    self.images[random_id] = image\n                    return_images.append(tmp)\n                else:       # 50% chance to return the current image\n                    return_images.append(image)\n        \n        return_images = torch.cat(return_images, 0)\n        return return_images\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.779112Z","iopub.execute_input":"2025-07-21T21:52:38.779438Z","iopub.status.idle":"2025-07-21T21:52:38.802875Z","shell.execute_reply.started":"2025-07-21T21:52:38.779410Z","shell.execute_reply":"2025-07-21T21:52:38.801527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CycleGANTrainer:\n    def __init__(self, G_AB, G_BA, D_A, D_B,\n                 dataloaders, optimizers,\n                 pool_size=50, device='cuda',\n                 output_dir='./outputs', img_save_epoch=5):\n        self.G_AB, self.G_BA = G_AB, G_BA\n        self.D_A, self.D_B = D_A, D_B\n        self.train_loader, self.val_loader = dataloaders\n        self.opt_G, self.opt_D = optimizers\n        self.device = device\n        self.best_ssim = -float('inf')\n        self.output_dir = output_dir\n        self.img_save_epoch = img_save_epoch\n        self.fake_A_pool = ImagePool(pool_size)\n        self.fake_B_pool = ImagePool(pool_size)\n\n        os.makedirs(output_dir, exist_ok=True)\n        os.makedirs(f\"{output_dir}/checkpoints\", exist_ok=True)\n        os.makedirs(f\"{output_dir}/images\", exist_ok=True)\n\n        self.loss_history = {'G': [], 'D': [], 'cycle': [], 'ssim': []}\n        self.G_AB = self.G_AB.to(self.device)\n        self.G_BA = self.G_BA.to(self.device)\n        self.D_A = self.D_A.to(self.device)\n        self.D_B = self.D_B.to(self.device)\n\n    def train(self, n_epochs, metrics_fn):\n        self.G_AB.train()\n        self.G_BA.train()\n        self.D_A.train()\n        self.D_B.train()\n        for epoch in range(1, n_epochs+1):\n            epoch_losses = {'G': 0., 'D': 0., 'cycle': 0., 'ssim': 0.}\n            pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch}/{n_epochs}\")\n            for real_A, real_B in pbar:\n                real_A, real_B = real_A.to(self.device), real_B.to(self.device)\n\n                # ------------------\n                #  Train Generators\n                # ------------------\n                self.opt_G.zero_grad()\n                fake_B = self.G_AB(real_A)\n                fake_A = self.G_BA(real_B)\n\n                rec_A = self.G_BA(fake_B)\n                rec_B = self.G_AB(fake_A)\n\n                # GAN losses\n                loss_GAN_AB = F.mse_loss(self.D_B(fake_B), torch.ones_like(self.D_B(fake_B)))\n                loss_GAN_BA = F.mse_loss(self.D_A(fake_A), torch.ones_like(self.D_A(fake_A)))\n\n                # Cycle consistency\n                loss_cycle = F.l1_loss(rec_A, real_A) + F.l1_loss(rec_B, real_B)\n\n                # Combined generator loss (no identity term)\n                loss_G = loss_GAN_AB + loss_GAN_BA + 10.0 * loss_cycle\n                loss_G.backward()\n                self.opt_G.step()\n\n                # -----------------------\n                #  Train Discriminators\n                # -----------------------\n                self.opt_D.zero_grad()\n                fake_B_ = self.fake_B_pool.query(fake_B.detach())\n                fake_A_ = self.fake_A_pool.query(fake_A.detach())\n\n                loss_D_B = (F.mse_loss(self.D_B(real_B), torch.ones_like(self.D_B(real_B))) +\n                                  F.mse_loss(self.D_B(fake_B_), torch.zeros_like(self.D_B(fake_B_))))\n                loss_D_A = (F.mse_loss(self.D_A(real_A), torch.ones_like(self.D_A(real_A))) +\n                                  F.mse_loss(self.D_A(fake_A_), torch.zeros_like(self.D_A(fake_A_))))\n                loss_D = loss_D_A + loss_D_B\n                loss_D.backward()\n                self.opt_D.step()\n\n                # Logging\n                epoch_losses['G'] += loss_G.item()\n                epoch_losses['D'] += loss_D.item()\n                epoch_losses['cycle'] += loss_cycle.item()\n                pbar.set_postfix(G=loss_G.item(), D=loss_D.item())\n\n            # Average losses\n            for k in ['G', 'D', 'cycle']:\n                epoch_losses[k] /= len(self.train_loader)\n\n            # Validation: compute SSIM on a small batch\n            val_real_A, val_real_B = next(iter(self.val_loader))\n            val_real_A, val_real_B = val_real_A.to(self.device), val_real_B.to(self.device)\n            val_fake_B = self.G_AB(val_real_A)\n            ssim_val = metrics_fn(val_fake_B, val_real_B)\n            epoch_losses['ssim'] = ssim_val\n\n            # Save best checkpoint\n            if ssim_val > self.best_ssim:\n                self.best_ssim = ssim_val\n                torch.save({\n                    'epoch': epoch,\n                    'G_AB': self.G_AB.state_dict(),\n                    'G_BA': self.G_BA.state_dict(),\n                    'D_A': self.D_A.state_dict(),\n                    'D_B': self.D_B.state_dict(),\n                    'opt_G': self.opt_G.state_dict(),\n                    'opt_D': self.opt_D.state_dict(),\n                    'best_ssim': self.best_ssim\n                }, f\"{self.output_dir}/checkpoints/best.pth\")\n\n            # Save epoch checkpoint\n            torch.save({\n                'epoch': epoch,\n                'G_AB': self.G_AB.state_dict(),\n                'G_BA': self.G_BA.state_dict(),\n                'D_A': self.D_A.state_dict(),\n                'D_B': self.D_B.state_dict(),\n                'opt_G': self.opt_G.state_dict(),\n                'opt_D': self.opt_D.state_dict(),\n                'best_ssim': self.best_ssim\n            }, f\"{self.output_dir}/checkpoints/epoch_{epoch}.pth\")\n\n            # Save sample images periodically\n            # if epoch % self.img_save_epoch == 0:\n            #     self.save_sample_images(epoch, num_samples=3)\n\n            # Record loss history\n            for k in ['G', 'D', 'cycle', 'ssim']:\n                self.loss_history[k].append(epoch_losses[k])\n\n            print(f\"Epoch {epoch} | SSIM: {ssim_val:.4f}\")\n\n        return self.loss_history\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.804225Z","iopub.execute_input":"2025-07-21T21:52:38.804590Z","iopub.status.idle":"2025-07-21T21:52:38.828402Z","shell.execute_reply.started":"2025-07-21T21:52:38.804560Z","shell.execute_reply":"2025-07-21T21:52:38.827480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import piq\ndef ssim_metric(pred, target):\n    # pred and target are in [–1,1] range; data_range=2.0 covers that span\n    p = torch.clamp((pred + 1.0) / 2.0, 0.0, 1.0)\n    t = torch.clamp((target + 1.0) / 2.0, 0.0, 1.0)\n    return piq.ssim(p, t, data_range=1.0, reduction='mean').item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.829306Z","iopub.execute_input":"2025-07-21T21:52:38.829633Z","iopub.status.idle":"2025-07-21T21:52:38.850810Z","shell.execute_reply.started":"2025-07-21T21:52:38.829599Z","shell.execute_reply":"2025-07-21T21:52:38.849781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import itertools","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.851764Z","iopub.execute_input":"2025-07-21T21:52:38.852001Z","iopub.status.idle":"2025-07-21T21:52:38.867428Z","shell.execute_reply.started":"2025-07-21T21:52:38.851982Z","shell.execute_reply":"2025-07-21T21:52:38.866501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = SARToEODataset(sar_paths, eo_paths, output_mode='RGB')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.868378Z","iopub.execute_input":"2025-07-21T21:52:38.868651Z","iopub.status.idle":"2025-07-21T21:52:38.884557Z","shell.execute_reply.started":"2025-07-21T21:52:38.868622Z","shell.execute_reply":"2025-07-21T21:52:38.883543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.885611Z","iopub.execute_input":"2025-07-21T21:52:38.885924Z","iopub.status.idle":"2025-07-21T21:52:38.903185Z","shell.execute_reply.started":"2025-07-21T21:52:38.885891Z","shell.execute_reply":"2025-07-21T21:52:38.901904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=1, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.904578Z","iopub.execute_input":"2025-07-21T21:52:38.904941Z","iopub.status.idle":"2025-07-21T21:52:38.920307Z","shell.execute_reply.started":"2025-07-21T21:52:38.904910Z","shell.execute_reply":"2025-07-21T21:52:38.919281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gen_params  = itertools.chain(G_sar2rgb.parameters(), G_rgb2sar.parameters())\ndisc_params = itertools.chain(D_sar.parameters(),     D_rgb.parameters())\n\noptimizer_G = torch.optim.AdamW(gen_params,  lr=2e-4,\n                                betas=(0.5, 0.999), weight_decay=1e-4)\noptimizer_D = torch.optim.AdamW(disc_params, lr=2e-4,\n                                betas=(0.5, 0.999), weight_decay=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.921297Z","iopub.execute_input":"2025-07-21T21:52:38.921580Z","iopub.status.idle":"2025-07-21T21:52:38.939512Z","shell.execute_reply.started":"2025-07-21T21:52:38.921558Z","shell.execute_reply":"2025-07-21T21:52:38.938484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CycleGANTrainer(\n    G_sar2rgb, G_rgb2sar, D_sar, D_rgb,\n    dataloaders=(train_loader, val_loader),\n    optimizers=(optimizer_G, optimizer_D),\n    pool_size=50,\n    device=device,\n    output_dir='./runs/exp1',\n    img_save_epoch=5\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.942952Z","iopub.execute_input":"2025-07-21T21:52:38.943331Z","iopub.status.idle":"2025-07-21T21:52:38.961890Z","shell.execute_reply.started":"2025-07-21T21:52:38.943305Z","shell.execute_reply":"2025-07-21T21:52:38.961077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_history = trainer.train(15,ssim_metric)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T21:52:38.962917Z","iopub.execute_input":"2025-07-21T21:52:38.963902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}